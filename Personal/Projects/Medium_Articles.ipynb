{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_RAW_DATASET = False\n",
    "tqdm.pandas(desc='')\n",
    "DIR = './data/medium_articles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_RAW_DATASET: dataframe = pd.read_csv(DIR + 'medium_articles.csv')\n",
    "else: dataframe = pd.read_csv(DIR + 'medium_articles_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub('\\'', '', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(lemmatizer.lemmatize(word)) for word in text]\n",
    "    text = [word for word in text if word not in eng_stopwords]\n",
    "\n",
    "    text = ' '.join(text).split('\\n')\n",
    "\n",
    "    return ' '.join(text)\n",
    "\n",
    "def process_tag(raw_tags: str):\n",
    "    raw_tags = raw_tags.replace('\\'', '').strip('[]').split(',')\n",
    "    for i in range(len(raw_tags)):\n",
    "        raw_tags[i] = raw_tags[i].strip()\n",
    "    return raw_tags\n",
    "\n",
    "def remove_rare_tags(tags: list, tags_list):\n",
    "    tags = [tag for tag in tags if tag in tags_list]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192367/192367 [00:00<00:00, 663057.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>photo josh riemer unsplash merri christma happ...</td>\n",
       "      <td>[Mental Health, Health, Psychology, Science, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brain coronaviru guid curiou troubl impact pan...</td>\n",
       "      <td>[Mental Health, Coronavirus, Science, Psycholo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mind nose smell train chang brain six week whi...</td>\n",
       "      <td>[Biotechnology, Neuroscience, Brain, Wellness,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passion synergi scienc technolog provid better...</td>\n",
       "      <td>[Health, Neuroscience, Mental Health, Psycholo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heard phinea gage railroad worker surviv explo...</td>\n",
       "      <td>[Brain, Health, Development, Psychology, Science]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  photo josh riemer unsplash merri christma happ...   \n",
       "1  brain coronaviru guid curiou troubl impact pan...   \n",
       "2  mind nose smell train chang brain six week whi...   \n",
       "3  passion synergi scienc technolog provid better...   \n",
       "4  heard phinea gage railroad worker surviv explo...   \n",
       "\n",
       "                                                tags  \n",
       "0  [Mental Health, Health, Psychology, Science, N...  \n",
       "1  [Mental Health, Coronavirus, Science, Psycholo...  \n",
       "2  [Biotechnology, Neuroscience, Brain, Wellness,...  \n",
       "3  [Health, Neuroscience, Mental Health, Psycholo...  \n",
       "4  [Brain, Health, Development, Psychology, Science]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop(['title', 'timestamp', 'authors', 'category'], axis=1, inplace=True)\n",
    "dataframe = dataframe[dataframe['text'].isna() == False]\n",
    "if LOAD_RAW_DATASET: dataframe['text'] = dataframe['text'].progress_apply(clean_text)\n",
    "dataframe['tags'] = dataframe['tags'].progress_apply(process_tag)\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192367/192367 [00:05<00:00, 38061.50it/s]\n"
     ]
    }
   ],
   "source": [
    "tags_dict = {}\n",
    "tag_occurence_treshold = 200\n",
    "for tags in dataframe['tags']:\n",
    "    for tag in tags:\n",
    "        if tag not in tags_dict:\n",
    "            tags_dict[tag] = 1\n",
    "        else:\n",
    "            tags_dict[tag] += 1\n",
    "\n",
    "tags = [key for key, value in tags_dict.items() if value > tag_occurence_treshold]\n",
    "dataframe['tags'] = dataframe['tags'].progress_apply(lambda x: remove_rare_tags(x, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(dataframe['tags'])\n",
    "y = mlb.transform(dataframe['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataframe['text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10_000)\n",
    "x_train_vectorized = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153893, 10000)\n",
      "(153893, 1215)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_vectorized.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(LogisticRegression())\n",
    "classifier.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  2.96%\n",
      "Test score:  2.97%\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {classifier.score(x_train_vectorized, y_train): .2%}')\n",
    "print(f'Test score: {classifier.score(x_test_vectorized, y_test): .2%}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19217652c784c0eb9511f8f5b096e4f8c7203998629d570e7b12322847e1aa51"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
